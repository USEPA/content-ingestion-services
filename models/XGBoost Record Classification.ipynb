{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(base_dir=\"/home/ubuntu/training_data\"):\n",
    "    train_texts = []\n",
    "    train_labels = []\n",
    "    label_counts = {}\n",
    "    for subdir, dirs, files in os.walk(base_dir):\n",
    "        label = subdir.split(r\"/\")[-1]\n",
    "        for f in files:\n",
    "            if f.split('.')[-1] == 'txt' and '-description.txt' not in f and '-guidance.txt' not in f:\n",
    "                path = os.path.join(subdir, f)\n",
    "                train_texts.append(path)\n",
    "                train_labels.append(label)\n",
    "                if label not in label_counts:\n",
    "                    label_counts[label] = 1\n",
    "                else:\n",
    "                    label_counts[label] += 1\n",
    "    label_counts = {k: v for k, v in sorted(label_counts.items(), key=lambda item: -item[1])}\n",
    "\n",
    "    return train_texts, train_labels, label_counts\n",
    "\n",
    "train_files, train_labels, label_counts = get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels = set([])\n",
    "for k, v in label_counts.items():\n",
    "    if v > 100:\n",
    "        valid_labels.add(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_files = []\n",
    "filtered_labels = []\n",
    "for i in range(len(train_files)):\n",
    "    if train_labels[i] in valid_labels:\n",
    "        filtered_files.append(train_files[i])\n",
    "        filtered_labels.append(train_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(filtered_files, filtered_labels, test_size=.2, shuffle=True, random_state=11235)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "shutil.rmtree('/home/ubuntu/train_split')\n",
    "os.mkdir('/home/ubuntu/train_split/')\n",
    "shutil.rmtree('/home/ubuntu/test_split')\n",
    "os.mkdir('/home/ubuntu/test_split/')\n",
    "for label in valid_labels:\n",
    "    if not os.path.isdir('/home/ubuntu/train_split/' + label):\n",
    "        os.mkdir('/home/ubuntu/train_split/' + label)\n",
    "    if not os.path.isdir('/home/ubuntu/test_split/' + label):\n",
    "        os.mkdir('/home/ubuntu/test_split/' + label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in train_files:\n",
    "    dest = '/home/ubuntu/train_split/' + r'/'.join(f.split(r'/')[-2:])\n",
    "    shutil.copyfile(f, dest)\n",
    "for f in test_files:\n",
    "    dest = '/home/ubuntu/test_split/' + r'/'.join(f.split(r'/')[-2:])\n",
    "    shutil.copyfile(f, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(file, text_size=4000):\n",
    "    t = \"\"\n",
    "    with open(file, 'r', encoding=\"utf-8\") as r:\n",
    "        t = r.read()[:text_size]\n",
    "    return t\n",
    "\n",
    "train_texts = [read_text(f) for f in train_files]\n",
    "test_texts = [read_text(f) for f in test_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertModel\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "model.eval()\n",
    "model.to('cuda')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used, somehow slower to batch\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "batched = list(batch(train_texts, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = [tokenizer(t, truncation=True, padding=True, return_tensors=\"pt\") for t in train_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokens = [tokenizer(t, truncation=True, padding=True, return_tensors=\"pt\") for t in test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(tokenized_text):\n",
    "    outputs = model(**(tokenized_text.to('cuda')))\n",
    "    embedding = outputs[0][:,0,:].detach().cpu().numpy()\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10491"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(data):  \n",
    "    embeddings = None\n",
    "    count = 0\n",
    "    for i in range(len(data)):\n",
    "        count += 1\n",
    "        embedding = embed(data[i])\n",
    "        if embeddings is None:\n",
    "            embeddings = embedding\n",
    "        else:\n",
    "            embeddings = np.append(embeddings, embedding, axis=0)\n",
    "        if count % 1000 == 0:\n",
    "            print(count)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = get_embeddings(train_tokens)\n",
    "test_embeddings = get_embeddings(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(data=train_embeddings)\n",
    "test = pd.DataFrame(data=test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label'] = train_labels\n",
    "test['label'] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv', index=False)\n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=0,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)',\n",
       "              n_estimators=200, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='gpu_hist', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(max_depth=3, n_estimators=200, tree_method='gpu_hist')\n",
    "\n",
    "train_y = train['label']\n",
    "train_x = train.drop(['label'], axis=1)\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test['label']\n",
    "test_x = test.drop(['label'], axis=1)\n",
    "test_probs = clf.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_accuracy(true_labels, predictions, model, k=3):\n",
    "    ind = np.argpartition(predictions, -k, axis=1)[:,-k:]\n",
    "    top_k_match = [(true_labels[i] in model.classes_[ind][i]) for i in range(len(true_labels))]\n",
    "    return np.mean(top_k_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5841197216661901"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_accuracy(test_y, test_probs, clf, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8147936326374988"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_accuracy(test_y, test_probs, clf, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8866647602707082"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_accuracy(test_y, test_probs, clf, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.892183031458532"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_probs = clf.predict_proba(train_x)\n",
    "top_k_accuracy(train_y, train_probs, clf, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = sklearn.metrics.confusion_matrix(filtered_test_label, clf.predict(filtered_test_x), labels=list(label_counts.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = pd.DataFrame(conf_matrix, index=list(label_counts.index), columns=['predicted ' + x for x in list(label_counts.index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
